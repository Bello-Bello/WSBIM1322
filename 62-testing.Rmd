# Hypothesis testing {#sec:testing}

For prerequisites within the Biomedical sciences masters degree at the
UCLouvain, see *WFARM1247* (Traitement statistique des donn√©es).

## Refresher

```{r toss, echo = FALSE}
set.seed(2) 
n <- 100
p <- 0.59
flips <- sample(c("H", "T"), size = n,
                replace = TRUE,
                prob = c(p, 1 - p))
```

We have flipped a coing 100 times and have obtained the following results.

```{r tossres, echo = FALSE}
table(flips)
```

If the coin were unbiased we expect roughly 50 heads. Can we make any
claims regarding the biaised or unbiaised nature of that coin?

A coin toss can be modeled by a binomial distribution. The histogram
below shows the binomial statistic for 0 to 100 heads; it represents
the binomial density of for an unbiased coin. The vertical line shows
the number of head observed.


```{r tosshist, echo = FALSE, fig.cap = "Binomial density of for an unbiased coin to get 0 to 100 heads. The full area of the histogram sums to 1."}
num_heads <- sum(flips == "H")
binomial_dens <-
    tibble(k = 0:n) %>%
    mutate(p = dbinom(k, size = n, prob = 0.5))

ggplot(binomial_dens, aes(x = k, y = p)) +
    geom_bar(stat = "identity") +
    geom_vline(xintercept = num_heads)
```

Above, we see that the most likely outcome would be 50 heads with a
probability of `r max(binomial_dens$p)`. No head and 100 heads have respectively 
`r binomial_dens$p[binomial_dens$k == 0]` and 
`r binomial_dens$p[binomial_dens$k == 100]` probability.

We set

- $H_0$: the coin is fair
- $H_1$: the coin is baised

If `r num_heads` isn't deemed too *extreme*, then we won't reject $H_0$ and 
conclude that the coin in faire. If `r num_heads`, then we reject $H_0$ and 
accept $H_1$, and conclude that the coin is baised.

To define *extreme*, we set $\alpha = 0.05$ and rejet $H_0$ if our result is 
outside of the 95% most probably values. 

```{r tossstat, echo = FALSE}
alpha <- 0.05
binomial_dens <-
    arrange(binomial_dens, p) %>%
    mutate(reject = (cumsum(p) <= alpha))
```

```{r tosshist2, echo = FALSE, fig.cap = "Binomial density of for an unbiased coin to get 0 to 100 heads. The areas in red sum to 0.05."}
ggplot(binomial_dens) +
    geom_bar(aes(x = k, y = p, fill = reject), stat = "identity") +
    scale_fill_manual(
        values = c(`TRUE` = "red", `FALSE` = "#5a5a5a")) + 
    geom_vline(xintercept = num_heads, col = "blue") +
    theme(legend.position = "none")
```

We can also compute the p-value, the tells us how likely we are to see
such a extreme or more extreme value under $H_0$.

```{r binom_test}
binom.test(x = 62, n = 100, p = 0.5)
```

See below for a step by step guide to this example.

## A biological example

We are going to use the `tdata1` dataset from the `rWSBIM1322` package
that provide gene expression data for 100 genes and 6 samples, three
in group A and 3 in group B.

```{r}
library("rWSBIM1322")
data(tdata2)
head(tdata1)
```

`r msmbstyle::question_begin()`
Visualise the distribution of the `tdata1` data and, if necessary,
log-transform it.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin()`
```{r tex1}
log_tdata1 <- log2(tdata1)
par(mfrow = c(1, 2))
limma::plotDensities(tdata1)
limma::plotDensities(log_tdata1)
```
`r msmbstyle::solution_end()`


We are now going to apply a t-test to feature 73, comparing the
expression intensities in groups A and B. In R, this can be done with
the `t.test` function:

```{r}
x <- log_tdata1[73, ]
t.test(x[1:3], x[4:6])
```

`r msmbstyle::question_begin()`
- Interpret the results of the test above.
- Repeat it on another features.
`r msmbstyle::question_end()`


`r msmbstyle::question_begin()`
We would now like to repeat the same analysis on the 100 genes. 
- Write a function that will take a vector as input and perform a
  t-test of the first values (our group A) against the 3 last values
  (our group B) and returns the p-values.
- Apply the test to all the genes.
- How many significantly differentically expressed genes do you find?
  What features are of possible biological interest?
`r msmbstyle::question_end()`


```{r}
my_t_test <- function(x) {
    t.test(x[1:3], x[4:6])$p.value
}
pvals <- apply(log_tdata1, 1, my_t_test)
table(pvals < 0.05)
head(sort(pvals))
```

`r msmbstyle::question_begin()`
The data above have been generated with the `rnorm` function for all
samples. 
- Do you still think any of the features show significant differences?
- Why are there still some features (around 5%) that show a
  significant p-value at an alpha of 0.05?
`r msmbstyle::question_end()`




```{r}
hist(pvals)
```

## Adjustment for multiple testing

Given the multitue of test, the type I error is not controlled
anymore. We need to take this into account and adjust the p-values for
multiple testing. Below we apply the Benjamini-Hochberg procedure
using the `p.adjust` function and confirm that none of the features
are differentially expressed.

```{r}
adj_pvals <- p.adjust(pvals, method = "BH")
any(adj_pvals < 0.05)
min(adj_pvals)
```

## Linear regression

## Empirical approximations 

- Bootstrapping to generate null distributions

## A word of caution

- p-hacking and p-harking


## Additional exercises

`r msmbstyle::question_begin()`
Generate random data using `rnorm` for 100 genes and 6 samples and
test for differential expression, comparing for each gene the 3 first
samples against the 3 last samples. Verify that you identify about 5
p-values smaller that 0.05. Visualise and interprete the histogramme
of these p-values.
`r msmbstyle::question_end()`


### The coin example, step by step {-}

> This step by step example is taken from Oliver Crook's intro lecture
> on statistics from the [2019 Bioinformatics Summer
> School](https://uclouvain-cbio.github.io/BSS2019/) at the UCLouvain.

The following code chunk simulates 100 coin toss from a biased coin.

```{r}
set.seed(2) 
n <- 100
p <- 0.59
flips <- sample(c("H", "T"), size = n,
                replace = TRUE,
                prob = c(p, 1 - p))
```

If the coin were unbiased we expect roughly 50 heads. Let us see how
many heads and tails there are.

```{r}
table(flips)
```

We calculate the binomial statistic for a number of flips between 0
and 100. This is the binomial density for an unbiased coin.

```{r}
library("dplyr")
num_heads <- sum(flips == "H")
binomial_dens <-
    tibble(k = 0:n) %>%
    mutate(p = dbinom(k, size = n, prob = 0.5))
```

`r msmbstyle::question_begin()`
- Write some code to check that the probabilties from the binomial
  statistic sum to $1$.

- Change the `prob` argument and show that the probabilities still sum
  to $1$.
`r msmbstyle::question_end()`

The following code chunk plots the binomial statistic and the number
of heads observed is marked in blue.


```{r,}
library("ggplot2")
ggplot(binomial_dens, aes(x = k, y = p)) +
    geom_bar(stat = "identity") +
    geom_vline(xintercept = num_heads)
```

`r msmbstyle::question_begin()`
- Change the prob argument above and re-plot the binomial statistic,
  what do you notice about how the distribution is centered?
`r msmbstyle::question_end()`

Now, we set the size of the reject threshold, this is a choice and
corresponds to how many false discoveries we are happy to allow.

```{r}
alpha <- 0.05
```

`r msmbstyle::question_begin()`
- Without looking below use the arrange function from `dplyr` to order
  the probabilities, smallest first.

- Looking at the output, what is the most unlikely number of heads to
  observe?

- Looking at the output, what is the most likely number of heads to
  observe?
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin()`
```{r}
binomial_dens %>%
    filter(p == max(p))

binomial_dens %>%
    filter(p == min(p))
```
`r msmbstyle::solution_end()`


`r msmbstyle::question_begin()`

- What does the following code chunk do?


```{r}
binomial_dens <-
    arrange(binomial_dens, p) %>%
    mutate(reject = (cumsum(p) <= alpha))

```
`r msmbstyle::question_end()`


Let us plot the reject region in red

```{r}
ggplot(binomial_dens) +
    geom_bar(aes(x = k, y = p, fill = reject), stat = "identity") +
    scale_fill_manual(
        values = c(`TRUE` = "red", `FALSE` = "#5a5a5a")) + 
    geom_vline(xintercept = num_heads, col = "blue") +
    theme(legend.position = "none")
```

`r msmbstyle::question_begin()`
- Is there evidence that our coin is biased?
- Change the size of the reject region to a smaller value, what is our
  conclusion now?
`r msmbstyle::question_end()`


The above test already has an easy to use funciton in R:

```{r}
binom.test(x = num_heads, n = n, p = 0.5)
```
