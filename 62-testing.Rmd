# Hypothesis testing {#sec:testing}

For prerequisites within the Biomedical sciences masters degree at the
UCLouvain, see *WFARM1247* (Traitement statistique des donn√©es).

## Refresher

```{r toss, echo = FALSE}
set.seed(2) 
n <- 100
p <- 0.59
flips <- sample(c("H", "T"), size = n,
                replace = TRUE,
                prob = c(p, 1 - p))
```

We have flipped a coing 100 times and have obtained the following results.

```{r tossres, echo = FALSE}
table(flips)
```

If the coin were unbiased we expect roughly 50 heads. Can we make any
claims regarding the biaised or unbiaised nature of that coin?

A coin toss can be modeled by a binomial distribution. The histogram
below shows the binomial statistic for 0 to 100 heads; it represents
the binomial density of for an unbiased coin. The vertical line shows
the number of head observed.


```{r tosshist, echo = FALSE, fig.cap = "Binomial density of for an unbiased coin to get 0 to 100 heads. The full area of the histogram sums to 1."}
num_heads <- sum(flips == "H")
binomial_dens <-
    tibble(k = 0:n) %>%
    mutate(p = dbinom(k, size = n, prob = 0.5))

ggplot(binomial_dens, aes(x = k, y = p)) +
    geom_bar(stat = "identity") +
    geom_vline(xintercept = num_heads)
```

Above, we see that the most likely outcome would be 50 heads with a
probability of `r max(binomial_dens$p)`. No head and 100 heads have respectively 
`r binomial_dens$p[binomial_dens$k == 0]` and 
`r binomial_dens$p[binomial_dens$k == 100]` probability.

We set

- $H_0$: the coin is fair
- $H_1$: the coin is baised

If `r num_heads` isn't deemed too *extreme*, then we won't reject $H_0$ and 
conclude that the coin in faire. If `r num_heads`, then we reject $H_0$ and 
accept $H_1$, and conclude that the coin is baised.

To define *extreme*, we set $\alpha = 0.05$ and rejet $H_0$ if our result is 
outside of the 95% most probably values. 

```{r tossstat, echo = FALSE}
alpha <- 0.05
binomial_dens <-
    arrange(binomial_dens, p) %>%
    mutate(reject = (cumsum(p) <= alpha))
```

```{r tosshist2, echo = FALSE, fig.cap = "Binomial density of for an unbiased coin to get 0 to 100 heads. The areas in red sum to 0.05."}
ggplot(binomial_dens) +
    geom_bar(aes(x = k, y = p, fill = reject), stat = "identity") +
    scale_fill_manual(
        values = c(`TRUE` = "red", `FALSE` = "#5a5a5a")) + 
    geom_vline(xintercept = num_heads, col = "blue") +
    theme(legend.position = "none")
```

We can also compute the p-value, the tells us how likely we are to see
such a extreme or more extreme value under $H_0$.

```{r binom_test}
binom.test(x = 62, n = 100, p = 0.5)
```

Whenever we make such a decision, we will be in one of the following situations:

|                     | $H_0$ is true           | $H_1$ is true            |
|---------------------|-------------------------|--------------------------|
| Reject $H_0$        | Type I (false positive) | True positive            |
| Do not reject $H_0$ | True negative           | Type II (false negative) |


See below for a step by step guide to this example.

## A biological example

A typical biological example consists in measuring a gene of interest
in two populations of interest (say control and group), represented by
biological replicates. The figure below represents the distribution of
the gene of interest in the two populations, with the expression
intensities of triplicates in each population. 

```{r exdists, echo = FALSE, fig.cap = "Expression of a gene in two populations with randomly chosen triplicates."}
set.seed(123)
s1 <- rnorm(3, 6, 1.2)
s2 <- rnorm(3, 11, 1.5)
tibble(groups = rep(c("control", "group"), each = 100),
       expression = c(rnorm(100, 6, 1.2), rnorm(100, 11, 1.5))) %>%
    ggplot(aes(x = expression, fill = groups, colour = groups)) +
    geom_density(alpha = 0.5) +
    geom_vline(xintercept = s1, colour = "#F8766D") +
    geom_vline(xintercept = s2, colour = "#00BFC4")
```

We don't have access to the whole population and thus use a sample
thereof (the replicated measurements) to estimate the population
parameters. We have

```{r extab, echo = FALSE}
df <- data.frame(control = s1, group = s2)
df <- rbind(df,
            c(mean(s1), mean(s2)),
            c(sd(s1), sd(s2)))
rownames(df) <- c(paste("rep", 1:3, sep = "."),
                  "mean", "sd")
knitr::kable(df)
```

We set our hypothesis as

- $H_0$: the means of the two groups are the same.
- $H_1$: the means of the two groups are different.

and calculate a two-sided, two-sample t-test (assuming unequal
variances) with

$$
t = \frac{ \bar X_{1} - \bar X_{2} }
         { \sqrt{ \frac{ s_{1}^{2} }{ N_{1} } \frac{ s_{2}^{2} }{ N_{2} } } }
$$


where $\bar X_i$, $s_{i}^{2}$ and $N_i$ are the mean, variance and size of samples 1 and 2. In R, we do this with

```{r}
t.test(s1, s2)
```

Note that in practice, we would apply moderated versions of the
t-test, such as the one provided in the `r Biocpkg("limma")` package 
and also widely applied to RNA-Seq count data.

## A more realistic biological example

Let's now use the `tdata1` dataset from the `rWSBIM1322` package that
provide gene expression data for 100 genes and 6 samples, three in
group A and 3 in group B.

```{r}
library("rWSBIM1322")
data(tdata1)
head(tdata1)
```

`r msmbstyle::question_begin()`
Visualise the distribution of the `tdata1` data and, if necessary,
log-transform it.
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin()`
```{r tex1}
log_tdata1 <- log2(tdata1)
par(mfrow = c(1, 2))
limma::plotDensities(tdata1)
limma::plotDensities(log_tdata1)
```
`r msmbstyle::solution_end()`

We are now going to apply a t-test to feature 73, comparing the
expression intensities in groups A and B. In R, this can be done with
the `t.test` function:


```{r}
x <- log_tdata1[73, ]
t.test(x[1:3], x[4:6])
```

`r msmbstyle::question_begin()`
- Interpret the results of the test above.
- Repeat it with another features.
`r msmbstyle::question_end()`


`r msmbstyle::question_begin()`
We would now like to repeat the same analysis on the 100 genes. 

- Write a function that will take a vector as input and perform a
  t-test of the first values (our group A) against the 3 last values
  (our group B) and returns the p-values.
  
- Apply the test to all the genes.

- How many significantly differentically expressed genes do you find?
  What features are of possible biological interest?
  
`r msmbstyle::question_end()`


`r msmbstyle::solution_begin()`
```{r}
my_t_test <- function(x) {
    t.test(x[1:3], x[4:6])$p.value
}
pvals <- apply(log_tdata1, 1, my_t_test)
table(pvals < 0.05)
head(sort(pvals))
```
`r msmbstyle::solution_end()`


`r msmbstyle::question_begin()`
The data above have been generated with the `rnorm` function for all
samples. 
- Do you still think any of the features show significant differences?
- Why are there still some features (around 5%) that show a
  significant p-value at an alpha of 0.05?
`r msmbstyle::question_end()`


To answer these questions, let's visualise the calculated p-values
with a histogramme.

```{r}
hist(pvals)
```

## Adjustment for multiple testing

Given the multitue of test, the type I error is not controlled
anymore. We need to take this into account and adjust the p-values for
multiple testing. Below we apply the Benjamini-Hochberg procedure
using the `p.adjust` function and confirm that none of the features
are differentially expressed.

```{r}
adj_pvals <- p.adjust(pvals, method = "BH")
any(adj_pvals < 0.05)
min(adj_pvals)
```

## Linear regression

## Empirical approximations 

- Bootstrapping to generate null distributions

## A word of caution

- p-hacking and p-harking


## Additional exercises

`r msmbstyle::question_begin()`
Generate random data using `rnorm` for 100 genes and 6 samples and
test for differential expression, comparing for each gene the 3 first
samples against the 3 last samples. Verify that you identify about 5
p-values smaller that 0.05. Visualise and interprete the histogramme
of these p-values.
`r msmbstyle::question_end()`


### The coin example, step by step {-}

> This step by step example is taken from Oliver Crook's intro lecture
> on statistics from the [2019 Bioinformatics Summer
> School](https://uclouvain-cbio.github.io/BSS2019/) at the UCLouvain.

The following code chunk simulates 100 coin toss from a biased coin.

```{r}
set.seed(2) 
n <- 100
p <- 0.59
flips <- sample(c("H", "T"), size = n,
                replace = TRUE,
                prob = c(p, 1 - p))
```

If the coin were unbiased we expect roughly 50 heads. Let us see how
many heads and tails there are.

```{r}
table(flips)
```

We calculate the binomial statistic for a number of flips between 0
and 100. This is the binomial density for an unbiased coin.

```{r}
library("dplyr")
num_heads <- sum(flips == "H")
binomial_dens <-
    tibble(k = 0:n) %>%
    mutate(p = dbinom(k, size = n, prob = 0.5))
```

`r msmbstyle::question_begin()`
- Write some code to check that the probabilties from the binomial
  statistic sum to $1$.

- Change the `prob` argument and show that the probabilities still sum
  to $1$.
`r msmbstyle::question_end()`

The following code chunk plots the binomial statistic and the number
of heads observed is marked in blue.


```{r,}
library("ggplot2")
ggplot(binomial_dens, aes(x = k, y = p)) +
    geom_bar(stat = "identity") +
    geom_vline(xintercept = num_heads)
```

`r msmbstyle::question_begin()`
- Change the prob argument above and re-plot the binomial statistic,
  what do you notice about how the distribution is centered?
`r msmbstyle::question_end()`

Now, we set the size of the reject threshold, this is a choice and
corresponds to how many false discoveries we are happy to allow.

```{r}
alpha <- 0.05
```

`r msmbstyle::question_begin()`
- Without looking below use the arrange function from `dplyr` to order
  the probabilities, smallest first.

- Looking at the output, what is the most unlikely number of heads to
  observe?

- Looking at the output, what is the most likely number of heads to
  observe?
`r msmbstyle::question_end()`

`r msmbstyle::solution_begin()`
```{r}
binomial_dens %>%
    filter(p == max(p))

binomial_dens %>%
    filter(p == min(p))
```
`r msmbstyle::solution_end()`


`r msmbstyle::question_begin()`

- What does the following code chunk do?


```{r}
binomial_dens <-
    arrange(binomial_dens, p) %>%
    mutate(reject = (cumsum(p) <= alpha))

```
`r msmbstyle::question_end()`


Let us plot the reject region in red

```{r}
ggplot(binomial_dens) +
    geom_bar(aes(x = k, y = p, fill = reject), stat = "identity") +
    scale_fill_manual(
        values = c(`TRUE` = "red", `FALSE` = "#5a5a5a")) + 
    geom_vline(xintercept = num_heads, col = "blue") +
    theme(legend.position = "none")
```

`r msmbstyle::question_begin()`
- Is there evidence that our coin is biased?
- Change the size of the reject region to a smaller value, what is our
  conclusion now?
`r msmbstyle::question_end()`


The above test already has an easy to use funciton in R:

```{r}
binom.test(x = num_heads, n = n, p = 0.5)
```
